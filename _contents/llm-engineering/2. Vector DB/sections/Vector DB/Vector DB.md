# Vector DB in LLM

## Summary
Vector DB는 LLM(대형 언어 모델)의 핵심 구성 요소로, 고차원 벡터 데이터를 효율적으로 저장하고 검색하는 데 사용됩니다. 벡터 데이터베이스는 자연어 처리, 추천 시스템, 컴퓨터 비전 등 다양한 AI 애플리케이션에서 사용되며, 특히 LLM에서 중요한 역할을 합니다. 벡터 데이터베이스는 문서의 의미적 내용을 이해하고, 관련된 문서를 검색하는 데 사용되며, LLM이 더 정확하고 유용한 응답을 생성할 수 있도록 지원합니다.

## Key Concepts
- **Vector DB의 정의** : 벡터 데이터베이스는 고차원 벡터 데이터를 저장하고 검색하는 데 사용되는 특수한 데이터베이스입니다.
- **LLM에서의 역할** : 벡터 데이터베이스는 LLM이 문서의 의미적 내용을 이해하고, 관련된 문서를 검색하는 데 사용됩니다.
- **벡터 임베딩** : 벡터 임베딩은 문서의 의미적 내용을 벡터로 표현하는 방법으로, 벡터 데이터베이스에서 사용됩니다.
- **유사성 검색** : 벡터 데이터베이스는 유사성 검색을 지원하여, LLM이 관련된 문서를 검색할 수 있도록 합니다.

## References
| URL 이름 | URL |
| --- | --- |
| Reddit - Generating useful context for llm | https://www.reddit.com/r/vectordatabase/comments/1cm7xcn/generating_useful_context_for_llm/ |
| Reddit - Is LLM necessary for RAG if we can retreive answer from vector... | https://www.reddit.com/r/LocalLLaMA/comments/1avayel/is_llm_necessary_for_rag_if_we_can_retreive/ |
| CrateDB - LLM Vector Database: What is a Vector Databases for LLM | https://cratedb.com/blog/llm-vector-database-what-is-a-vector-databases-for-llm |
| Qwak - Integrating Vector Databases with LLMs: A Hands-On Guide | https://www.qwak.com/post/utilizing-llms-with-embedding-stores |
| Stack Overflow - use embeddings stored in vector db to reduce work for LLM | https://stackoverflow.com/questions/78023750/use-embeddings-stored-in-vector-db-to-reduce-work-for-llm-generating-response |