# 1. Transformer 아키텍쳐

## Summary
Transformer 아키텍쳐는 인공신경망의 한 유형으로, 주로 자연어 처리(NLP)에서 사용됩니다. 이 아키텍쳐는 인코더(Encoder)와 디코더(Decoder) 두 부분으로 구성되어 있으며, 인코더는 입력 텍스트를 처리하여 컨텍스트 정보를 추출하고, 디코더는 이 정보를 사용하여 출력 텍스트를 생성합니다. Transformer는 기존의 순환 신경망(RNN)과 달리, 병렬 처리가 가능하여 학습 속도가 빠르고, 긴 시퀀스를 처리할 수 있습니다.

## Key Concepts
- **인코더(Encoder)** : 입력 텍스트를 처리하여 컨텍스트 정보를 추출하는 부분입니다.
- **디코더(Decoder)** : 인코더에서 추출한 컨텍스트 정보를 사용하여 출력 텍스트를 생성하는 부분입니다.
- **셀프-어텐션(self-attention)** : 입력 데이터의 각 요소가 다른 모든 요소와의 관계를 고려하여 처리하는 메커니즘입니다.
- **포지셔널 인코딩(positional encoding)** : 입력 데이터의 순서 정보를 추가하여 처리하는 방법입니다.
- **레이어 노멀라이제이션(layer normalization)** : 각 레이어의 출력을 정규화하여 학습의 안정성을 향상시키는 기법입니다.

## References
|URL 이름|URL|
|---|---|
|DataCamp - How Transformers Work|https://www.datacamp.com/tutorial/how-transformers-work|
|TrueFoundry - Transformer Architecture|https://www.truefoundry.com/blog/transformer-architecture|
|MLQ.ai - Understanding Transformers & the Architecture of LLMs|https://blog.mlq.ai/llm-transformer-architecture/|
|Wikipedia - Transformer (deep learning architecture)|https://en.wikipedia.org/wiki/Transformer_%28deep_learning_architecture%29|
|YouTube - LLM Chronicles #5.1: The Transformer Architecture|https://www.youtube.com/watch?v=GhdB7UMtGqs|