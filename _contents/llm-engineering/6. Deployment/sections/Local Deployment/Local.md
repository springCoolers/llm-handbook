# Local in LLM

## Summary
"Local in LLM"는 로컬 환경에서 대형 언어 모델(Large Language Model, LLM)을 실행하는 개념을 가리킵니다. 이 개념은 사용자가 자신의 컴퓨터에서 LLM을 실행하여 데이터의 프라이버시를 유지하고, 인터넷 연결 없이도 모델을 사용할 수 있도록 합니다. 다양한 도구와 플랫폼이 로컬 LLM을 지원하며, 사용자는 자신의 필요와 전문성에 따라 적절한 도구를 선택할 수 있습니다.

## Key Concepts
- **로컬 실행**: 사용자가 자신의 컴퓨터에서 LLM을 실행하여 인터넷 연결 없이도 모델을 사용할 수 있습니다.
- **프라이버시**: 로컬 LLM을 사용하면 데이터가 외부 서버로 전송되지 않아 프라이버시를 유지할 수 있습니다.
- **모델 선택**: 다양한 도구와 플랫폼이 로컬 LLM을 지원하며, 사용자는 자신의 필요와 전문성에 따라 적절한 도구를 선택할 수 있습니다.

## References
| URL Name | URL |
| --- | --- |
| Jeremy Morgan's Blog | https://www.jeremymorgan.com/blog/generative-ai/local-llm-ubuntu/ |
| GPT4All Discussion | https://github.com/nomic-ai/gpt4all/discussions/2349 |
| Puget Systems Tech Primer | https://www.pugetsystems.com/labs/articles/tech-primer-what-hardware-do-you-need-to-run-a-local-llm/ |
| InfoWorld Article | https://www.infoworld.com/article/2338922/5-easy-ways-to-run-an-llm-locally.html |
| Semaphore CI Blog | https://semaphoreci.com/blog/local-llm |