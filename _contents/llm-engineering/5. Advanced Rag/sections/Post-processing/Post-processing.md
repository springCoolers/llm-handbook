# LLM의 후처리(Post-processing)

## 개요
LLM의 후처리는 모델의 출력을 개선하고, 사용자 요구에 맞추기 위한 추가적인 단계입니다. 이 과정은 모델의 성능을 향상시키고, 오류를 줄이기 위해 사용됩니다. 후처리는 다양한 방법으로 수행될 수 있으며, 모델의 출력을 정제하고, 사용자 요구에 맞추기 위한 중요한 단계입니다.

## 주요 개념
- **후처리 필요성** : LLM의 출력은 종종 추가적인 정제가 필요하며, 후처리는 이를 수행하는 중요한 단계입니다.
- **후처리 기법** : 후처리는 다양한 기법을 사용할 수 있으며, 이는 모델의 출력을 개선하고, 오류를 줄이기 위해 사용됩니다. 예를 들어, 규칙 기반 시스템, 정규 표현식, 의미 기반 분할 등이 있습니다.
- **후처리 적용** : 후처리는 모델의 출력을 정제하고, 사용자 요구에 맞추기 위해 적용됩니다. 이는 모델의 성능을 향상시키고, 오류를 줄이기 위해 사용됩니다.

## 참고 자료
| URL 이름 | URL |
| --- | --- |
| Unit8 - A new era of AI: a practical guide to Large Language Models | https://unit8.com/resources/a-new-era-of-ai-a-practical-guide-to-large-language-models/ |
| Buduroiu - Semantic Router: Postprocessing LLM output using Semantic Splitters | https://buduroiu.com/blog/semantic-router-splitter-postprocessing-llm-output/ |
| Neptune.ai - Customizing LLM Output: Post-Processing Techniques | https://neptune.ai/blog/customizing-llm-output-post-processing-techniques |
| reposiTUm - LLM Calibration: A Dual Approach of Post-Processing and Prompting Strategies | https://repositum.tuwien.at/bitstream/20.500.12708/198211/1/Vogl%20Bettina%20-%202024%20-%20LLM%20Calibration%20A%20Dual%20Approach%20of%20Post-Processing%20and...pdf |
| Megagon.ai - LLMs as Data Annotators (Part 1) - Challenges and Opportunities | https://megagon.ai/llms-as-data-annote-p1-challs-opps/ |