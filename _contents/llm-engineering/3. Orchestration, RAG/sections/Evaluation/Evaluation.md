# LLM 평가

## 요약
LLM 평가는 대형 언어 모델의 성능을 측정하고 개선하는 데 중요한 역할을 합니다. 평가 프로세스는 모델의 강점과 약점을 식별하고, 모델이 실제 응용 프로그램에서 효과적으로 작동하는지 확인하는 데 도움이 됩니다. 또한, 평가는 모델의 출력이 편향되거나 오해의 소지가 있는지 확인하고, 이러한 문제를 해결하는 전략을 개발하는 데 도움이 됩니다.

## 주요 개념
- **성능 평가** : LLM의 성능을 측정하고 개선하는 데 사용되는 다양한 메트릭과 방법론을 포함합니다. 이는 정확성, 유창성, 일관성, 관련성 등 다양한 측면을 평가합니다.
- **모델 비교** : 여러 LLM을 비교하고 선택하는 데 사용되는 평가 프레임워크와 도구를 포함합니다. 이는 모델의 강점과 약점을 식별하고, 모델을 특정 응용 프로그램에 맞게 최적화하는 데 도움이 됩니다.
- **편향 감지 및 완화** : LLM의 출력이 편향되거나 오해의 소지가 있는지 확인하고, 이러한 문제를 해결하는 전략을 개발하는 데 사용되는 평가 방법론을 포함합니다.
- **사용자 만족 및 신뢰** : LLM의 출력이 사용자의 기대에 부합하고 신뢰를 얻는지 평가하는 데 사용되는 메트릭과 방법론을 포함합니다.
- **벤치마킹** : LLM의 성능을 표준화된 벤치마크에 대해 평가하는 데 사용되는 방법론을 포함합니다.

## 참고자료
| URL 이름 | URL |
| --- | --- |
| Large Language Model Evaluation in 2024: 5 Methods | https://research.aimultiple.com/large-language-model-evaluation/ |
| Evaluating Large Language Models: A Complete Guide - SingleStore | https://www.singlestore.com/blog/complete-guide-to-evaluating-large-language-models/ |
| LLM Evaluation | Clarifai Docs | https://docs.clarifai.com/portal-guide/evaluate/llms/ |
| Evaluation metrics | Microsoft Learn | https://learn.microsoft.com/en-us/ai/playbook/technology-guidance/generative-ai/working-with-llms/evaluation/list-of-eval-metrics |
| LLM Evaluation Metrics : A Complete Guide to Evaluating LLMs | https://aisera.com/blog/llm-evaluation/ |