# 10. Finetuning For Llms

## Summary
Finetuning for LLMs는 사전 학습된 모델을 특정 작업이나 도메인에 맞게 조정하는 과정입니다. 이 과정은 모델의 성능을 향상시키고, 특정 작업에 대한 정확성을 높이는 데 도움이 됩니다. Finetuning은 다양한 방법으로 수행될 수 있으며, 이 중에는 감독 학습, 비감독 학습, 지침 기반 학습 등이 포함됩니다. 또한, 모델의 가중치를 업데이트하는 다양한 기술이 있으며, 이 중에는 전체 finetuning, 어댑터 기반 tuning, 매개변수 효율적인 finetuning 등이 있습니다.

## Key Concepts
- **Finetuning** : 사전 학습된 모델을 특정 작업이나 도메인에 맞게 조정하는 과정입니다.
- **Supervised Fine-Tuning** : 레이블이 있는 데이터를 사용하여 모델을 학습시키는 방법입니다.
- **Unsupervised Fine-Tuning** : 레이블이 없는 데이터를 사용하여 모델을 학습시키는 방법입니다.
- **Instruction Fine-Tuning** : 지침을 사용하여 모델을 학습시키는 방법입니다.
- **Full Fine-Tuning** : 모델의 모든 가중치를 업데이트하는 방법입니다.
- **Adapter-Based Tuning** : 모델의 일부 가중치를 업데이트하는 방법입니다.
- **Parameter-Efficient Fine-Tuning** : 모델의 일부 가중치를 업데이트하는 방법입니다.

## References
|URL Name|URL|
|---|---|
| The Ultimate Guide to Fine-Tuning LLMs|https://arxiv.org/html/2408.13296v1|
| Fine-tuning large language models (LLMs) in 2024 - SuperAnnotate|https://www.superannotate.com/blog/llm-fine-tuning|
| The Ultimate Guide to LLM Fine Tuning: Best Practices & Tools|https://www.lakera.ai/blog/llm-fine-tuning-guide|
| Finetuning in large language models - Oracle Blogs|https://blogs.oracle.com/ai-and-datascience/post/finetuning-in-large-language-models|