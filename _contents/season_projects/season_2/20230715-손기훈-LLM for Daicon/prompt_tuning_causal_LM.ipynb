{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "937565d0-a3c2-4552-a081-1e2a3d2cf138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /root/anaconda3/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda113.so\n",
      "CUDA SETUP: CUDA runtime path found: /root/anaconda3/lib/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 113\n",
      "CUDA SETUP: Loading binary /root/anaconda3/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/root/anaconda3/lib/libcudart.so.11.0'), PosixPath('/root/anaconda3/lib/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, default_data_collator, get_linear_schedule_with_warmup\n",
    "from peft import get_peft_config, get_peft_model, PromptTuningInit, PromptTuningConfig, TaskType, PeftType, prepare_model_for_int8_training, LoraConfig, get_peft_model_state_dict\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "import transformers\n",
    "import textwrap\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "import os\n",
    "import sys\n",
    "from typing import List\n",
    "import fire\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "device = \"cuda\"\n",
    "# # model_name_or_path = \"bigscience/bloomz-560m\"\n",
    "# # tokenizer_name_or_path = \"bigscience/bloomz-560m\"\n",
    "# peft_config = PromptTuningConfig(\n",
    "#     task_type=TaskType.CAUSAL_LM,\n",
    "#     prompt_tuning_init=PromptTuningInit.TEXT,\n",
    "#     num_virtual_tokens=8,\n",
    "#     tokenizer_name_or_path=model_name_or_path,\n",
    "# )\n",
    "\n",
    "# dataset_name = \"judge_data\"\n",
    "# checkpoint_name = f\"{dataset_name}_{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}_v1.pt\".replace(\n",
    "#     \"/\", \"_\"\n",
    "# )\n",
    "\n",
    "max_length = 64\n",
    "lr = 3e-2\n",
    "num_epochs = 50\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b2fa2be-56a8-4966-9ca4-55ca80607efc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ID': 'TRAIN_0001',\n",
      " 'answer': 'yes',\n",
      " 'input': 'Ramon Nelson was riding his bike when he suffered a lethal blow to '\n",
      "          'the back of his head with a baseball bat. After two eyewitnesses '\n",
      "          'identified Lawrence Owens from an array of photos and then a '\n",
      "          'lineup, he was tried and convicted for Nelson’s death. Because '\n",
      "          'Nelson was carrying cocaine and crack cocaine potentially for '\n",
      "          'distribution, the judge at Owens’ bench trial ruled that Owens was '\n",
      "          'probably also a drug dealer and was trying to “knock [Nelson] off.” '\n",
      "          'Owens was found guilty of first-degree murder and sentenced to 25 '\n",
      "          'years in prison.\\n'\n",
      "          'Owens filed a petition for a writ of habeas corpus on the grounds '\n",
      "          'that his constitutional right to due process was violated during '\n",
      "          'the trial. He argued that the eyewitness identification should have '\n",
      "          'been inadmissible based on unreliability and that the judge '\n",
      "          'impermissibly inferred a motive when a motive was not an element of '\n",
      "          'the offense. The district court denied the writ of habeas corpus, '\n",
      "          'and Owens appealed. The U.S. Court of Appeals for the Seventh '\n",
      "          'Circuit reversed the denial and held that the trial judge’s '\n",
      "          'inference about Owens’s motive violated his right to have his guilt '\n",
      "          'adjudicated solely based on the evidence presented at trial.\\n',\n",
      " 'is_first_in': 0,\n",
      " 'is_second_in': 1,\n",
      " 'label': 0,\n",
      " 'party': 'Lawrence Owens',\n",
      " 'prompt': 'Does Lawrence Owens win?'}\n",
      "yes\n",
      "{'instruction': 'Does Lawrence Owens win?', 'input': 'Ramon Nelson was riding his bike when he suffered a lethal blow to the back of his head with a baseball bat. After two eyewitnesses identified Lawrence Owens from an array of photos and then a lineup, he was tried and convicted for Nelson’s death. Because Nelson was carrying cocaine and crack cocaine potentially for distribution, the judge at Owens’ bench trial ruled that Owens was probably also a drug dealer and was trying to “knock [Nelson] off.” Owens was found guilty of first-degree murder and sentenced to 25 years in prison.\\nOwens filed a petition for a writ of habeas corpus on the grounds that his constitutional right to due process was violated during the trial. He argued that the eyewitness identification should have been inadmissible based on unreliability and that the judge impermissibly inferred a motive when a motive was not an element of the offense. The district court denied the writ of habeas corpus, and Owens appealed. The U.S. Court of Appeals for the Seventh Circuit reversed the denial and held that the trial judge’s inference about Owens’s motive violated his right to have his guilt adjudicated solely based on the evidence presented at trial.\\n', 'output': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import json\n",
    "from pprint import pprint\n",
    "with open('train_json.pickle', 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "train_dataset = dataset[\"root\"]\n",
    "pprint(train_dataset[0])\n",
    "\n",
    "print(train_dataset[0]['answer'])\n",
    "\n",
    "\n",
    "dataset = []\n",
    "for data in train_dataset:\n",
    "    a = {\n",
    "        'instruction' : f\"{data['prompt']}\",\n",
    "        'input' : data['input'],\n",
    "        'output' : data['answer']\n",
    "    }\n",
    "    dataset.append(a)\n",
    "\n",
    "    \n",
    "print(dataset[0])\n",
    "\n",
    "with open('alpaca_judge_train.json', 'w') as f:\n",
    "    json.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "315a5e45-82b7-48c6-9fd9-797313896410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'Ramon Nelson was riding his bike when he suffered a lethal blow to '\n",
      "          'the back of his head with a baseball bat. After two eyewitnesses '\n",
      "          'identified Lawrence Owens from an array of photos and then a '\n",
      "          'lineup, he was tried and convicted for Nelson’s death. Because '\n",
      "          'Nelson was carrying cocaine and crack cocaine potentially for '\n",
      "          'distribution, the judge at Owens’ bench trial ruled that Owens was '\n",
      "          'probably also a drug dealer and was trying to “knock [Nelson] off.” '\n",
      "          'Owens was found guilty of first-degree murder and sentenced to 25 '\n",
      "          'years in prison.\\n'\n",
      "          'Owens filed a petition for a writ of habeas corpus on the grounds '\n",
      "          'that his constitutional right to due process was violated during '\n",
      "          'the trial. He argued that the eyewitness identification should have '\n",
      "          'been inadmissible based on unreliability and that the judge '\n",
      "          'impermissibly inferred a motive when a motive was not an element of '\n",
      "          'the offense. The district court denied the writ of habeas corpus, '\n",
      "          'and Owens appealed. The U.S. Court of Appeals for the Seventh '\n",
      "          'Circuit reversed the denial and held that the trial judge’s '\n",
      "          'inference about Owens’s motive violated his right to have his guilt '\n",
      "          'adjudicated solely based on the evidence presented at trial.\\n',\n",
      " 'instruction': 'Does Lawrence Owens win?',\n",
      " 'output': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "pprint(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5578a44-3e9e-4e28-aaf9-1ef6186fe09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b735e4586934b919828ea7c2da728c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
      "The class this function is called from is 'LlamaTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "BASE_MODEL = \"decapoda-research/llama-7b-hf\"\n",
    " \n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    " \n",
    "tokenizer = LlamaTokenizer.from_pretrained(BASE_MODEL)\n",
    " \n",
    "tokenizer.pad_token_id = (\n",
    "    0  # unk. we want this to be different from the eos token\n",
    ")\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82919bc3-9734-40f0-9ef2-facf45811c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-a50c0b29362ec049/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62bb84355b4540c5af89acdb57535402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24d3aaa106f4bcca25210f830e14dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-a50c0b29362ec049/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e10d0022f8472ba508d2194bb5542b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output'],\n",
       "    num_rows: 2976\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_dataset(\"json\", data_files=\"alpaca_judge_train.json\")\n",
    "data[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc6c0b7a-8f9d-4dae-aadb-34d750a0439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(data_point):\n",
    "    return f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.  # noqa: E501\n",
    "### Instruction:\n",
    "{data_point[\"instruction\"]}\n",
    "### Input:\n",
    "{data_point[\"input\"]}\n",
    "### Response:\n",
    "{data_point[\"output\"]}\"\"\"\n",
    " \n",
    " \n",
    "def tokenize(prompt, add_eos_token=True):\n",
    "    result = tokenizer(\n",
    "        prompt,\n",
    "        truncation=True,\n",
    "        max_length=1024,\n",
    "        padding=False,\n",
    "        return_tensors=None,\n",
    "    )\n",
    "    if (\n",
    "        result[\"input_ids\"][-1] != tokenizer.eos_token_id\n",
    "        and len(result[\"input_ids\"]) < 1024\n",
    "        and add_eos_token\n",
    "    ):\n",
    "        result[\"input_ids\"].append(tokenizer.eos_token_id)\n",
    "        result[\"attention_mask\"].append(1)\n",
    " \n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    " \n",
    "    return result\n",
    " \n",
    "def generate_and_tokenize_prompt(data_point):\n",
    "    full_prompt = generate_prompt(data_point)\n",
    "    tokenized_full_prompt = tokenize(full_prompt)\n",
    "    return tokenized_full_prompt\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1e660152-2ef1-4470-9aeb-b7b1c2e038b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.  # noqa: E501\\n### Instruction:\\nDoes Lawrence Owens win?\\n### Input:\\nRamon Nelson was riding his bike when he suffered a lethal blow to the back of his head with a baseball bat. After two eyewitnesses identified Lawrence Owens from an array of photos and then a lineup, he was tried and convicted for Nelson’s death. Because Nelson was carrying cocaine and crack cocaine potentially for distribution, the judge at Owens’ bench trial ruled that Owens was probably also a drug dealer and was trying to “knock [Nelson] off.” Owens was found guilty of first-degree murder and sentenced to 25 years in prison.\\nOwens filed a petition for a writ of habeas corpus on the grounds that his constitutional right to due process was violated during the trial. He argued that the eyewitness identification should have been inadmissible based on unreliability and that the judge impermissibly inferred a motive when a motive was not an element of the offense. The district court denied the writ of habeas corpus, and Owens appealed. The U.S. Court of Appeals for the Seventh Circuit reversed the denial and held that the trial judge’s inference about Owens’s motive violated his right to have his guilt adjudicated solely based on the evidence presented at trial.\\n\\n### Response:\\nyes'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_prompt(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ba934f5-1ae8-40f4-9386-512a66aa7905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2776 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "train_val = data[\"train\"].train_test_split(\n",
    "    test_size=200, shuffle=True, seed=42\n",
    ")\n",
    "train_data = (\n",
    "    train_val[\"train\"].map(generate_and_tokenize_prompt)\n",
    ")\n",
    "val_data = (\n",
    "    train_val[\"test\"].map(generate_and_tokenize_prompt)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7515e65-ca9c-4cb1-a406-b378699a93ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "LORA_R = 8\n",
    "LORA_ALPHA = 16\n",
    "LORA_DROPOUT= 0.05\n",
    "LORA_TARGET_MODULES = [\n",
    "    \"q_proj\",\n",
    "    \"v_proj\",\n",
    "]\n",
    " \n",
    "BATCH_SIZE = 16\n",
    "MICRO_BATCH_SIZE = 4\n",
    "GRADIENT_ACCUMULATION_STEPS = BATCH_SIZE // MICRO_BATCH_SIZE\n",
    "LEARNING_RATE = 3e-4\n",
    "TRAIN_STEPS = 300\n",
    "OUTPUT_DIR = \"experiments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0bf588d-40e6-4f2d-8953-f9b3421f8a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4194304 || all params: 6742609920 || trainable%: 0.06220594176090199\n"
     ]
    }
   ],
   "source": [
    "model = prepare_model_for_int8_training(model)\n",
    "config = LoraConfig(\n",
    "    r=LORA_R,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    target_modules=LORA_TARGET_MODULES,\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = get_peft_model(model, config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89f8f728-14ba-4643-98f5-db9f159bc9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = transformers.TrainingArguments(\n",
    "    per_device_train_batch_size=MICRO_BATCH_SIZE,\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "    warmup_steps=100,\n",
    "    max_steps=TRAIN_STEPS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    optim=\"adamw_torch\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    save_steps=50,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"tensorboard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54bb1d1b-e1e5-481c-804b-d61f3b0badbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = transformers.DataCollatorForSeq2Seq(\n",
    "    tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3066ca8c-b168-43a8-9bf5-7bf9eaebed1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 1:03:04, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.348300</td>\n",
       "      <td>1.306234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.209000</td>\n",
       "      <td>1.228881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.195300</td>\n",
       "      <td>1.218913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.188500</td>\n",
       "      <td>1.213241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.144200</td>\n",
       "      <td>1.195231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.155400</td>\n",
       "      <td>1.190804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/root/anaconda3/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/root/anaconda3/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/root/anaconda3/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/root/anaconda3/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "There were missing keys in the checkpoint model loaded: ['base_model.model.model.embed_tokens.weight', 'base_model.model.model.layers.0.self_attn.q_proj.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.weight', 'base_model.model.model.layers.0.self_attn.v_proj.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.weight', 'base_model.model.model.layers.0.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.0.mlp.gate_proj.weight', 'base_model.model.model.layers.0.mlp.down_proj.weight', 'base_model.model.model.layers.0.mlp.up_proj.weight', 'base_model.model.model.layers.0.input_layernorm.weight', 'base_model.model.model.layers.0.post_attention_layernorm.weight', 'base_model.model.model.layers.1.self_attn.q_proj.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.weight', 'base_model.model.model.layers.1.self_attn.v_proj.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.o_proj.weight', 'base_model.model.model.layers.1.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.1.mlp.gate_proj.weight', 'base_model.model.model.layers.1.mlp.down_proj.weight', 'base_model.model.model.layers.1.mlp.up_proj.weight', 'base_model.model.model.layers.1.input_layernorm.weight', 'base_model.model.model.layers.1.post_attention_layernorm.weight', 'base_model.model.model.layers.2.self_attn.q_proj.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.weight', 'base_model.model.model.layers.2.self_attn.v_proj.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.o_proj.weight', 'base_model.model.model.layers.2.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.2.mlp.gate_proj.weight', 'base_model.model.model.layers.2.mlp.down_proj.weight', 'base_model.model.model.layers.2.mlp.up_proj.weight', 'base_model.model.model.layers.2.input_layernorm.weight', 'base_model.model.model.layers.2.post_attention_layernorm.weight', 'base_model.model.model.layers.3.self_attn.q_proj.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.weight', 'base_model.model.model.layers.3.self_attn.v_proj.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.o_proj.weight', 'base_model.model.model.layers.3.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.3.mlp.gate_proj.weight', 'base_model.model.model.layers.3.mlp.down_proj.weight', 'base_model.model.model.layers.3.mlp.up_proj.weight', 'base_model.model.model.layers.3.input_layernorm.weight', 'base_model.model.model.layers.3.post_attention_layernorm.weight', 'base_model.model.model.layers.4.self_attn.q_proj.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.weight', 'base_model.model.model.layers.4.self_attn.v_proj.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.o_proj.weight', 'base_model.model.model.layers.4.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.4.mlp.gate_proj.weight', 'base_model.model.model.layers.4.mlp.down_proj.weight', 'base_model.model.model.layers.4.mlp.up_proj.weight', 'base_model.model.model.layers.4.input_layernorm.weight', 'base_model.model.model.layers.4.post_attention_layernorm.weight', 'base_model.model.model.layers.5.self_attn.q_proj.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.weight', 'base_model.model.model.layers.5.self_attn.v_proj.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.o_proj.weight', 'base_model.model.model.layers.5.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.5.mlp.gate_proj.weight', 'base_model.model.model.layers.5.mlp.down_proj.weight', 'base_model.model.model.layers.5.mlp.up_proj.weight', 'base_model.model.model.layers.5.input_layernorm.weight', 'base_model.model.model.layers.5.post_attention_layernorm.weight', 'base_model.model.model.layers.6.self_attn.q_proj.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.weight', 'base_model.model.model.layers.6.self_attn.v_proj.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.o_proj.weight', 'base_model.model.model.layers.6.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.6.mlp.gate_proj.weight', 'base_model.model.model.layers.6.mlp.down_proj.weight', 'base_model.model.model.layers.6.mlp.up_proj.weight', 'base_model.model.model.layers.6.input_layernorm.weight', 'base_model.model.model.layers.6.post_attention_layernorm.weight', 'base_model.model.model.layers.7.self_attn.q_proj.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.weight', 'base_model.model.model.layers.7.self_attn.v_proj.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.o_proj.weight', 'base_model.model.model.layers.7.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.7.mlp.gate_proj.weight', 'base_model.model.model.layers.7.mlp.down_proj.weight', 'base_model.model.model.layers.7.mlp.up_proj.weight', 'base_model.model.model.layers.7.input_layernorm.weight', 'base_model.model.model.layers.7.post_attention_layernorm.weight', 'base_model.model.model.layers.8.self_attn.q_proj.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.weight', 'base_model.model.model.layers.8.self_attn.v_proj.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.o_proj.weight', 'base_model.model.model.layers.8.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.8.mlp.gate_proj.weight', 'base_model.model.model.layers.8.mlp.down_proj.weight', 'base_model.model.model.layers.8.mlp.up_proj.weight', 'base_model.model.model.layers.8.input_layernorm.weight', 'base_model.model.model.layers.8.post_attention_layernorm.weight', 'base_model.model.model.layers.9.self_attn.q_proj.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.weight', 'base_model.model.model.layers.9.self_attn.v_proj.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.o_proj.weight', 'base_model.model.model.layers.9.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.9.mlp.gate_proj.weight', 'base_model.model.model.layers.9.mlp.down_proj.weight', 'base_model.model.model.layers.9.mlp.up_proj.weight', 'base_model.model.model.layers.9.input_layernorm.weight', 'base_model.model.model.layers.9.post_attention_layernorm.weight', 'base_model.model.model.layers.10.self_attn.q_proj.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.weight', 'base_model.model.model.layers.10.self_attn.v_proj.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.o_proj.weight', 'base_model.model.model.layers.10.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.10.mlp.gate_proj.weight', 'base_model.model.model.layers.10.mlp.down_proj.weight', 'base_model.model.model.layers.10.mlp.up_proj.weight', 'base_model.model.model.layers.10.input_layernorm.weight', 'base_model.model.model.layers.10.post_attention_layernorm.weight', 'base_model.model.model.layers.11.self_attn.q_proj.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.weight', 'base_model.model.model.layers.11.self_attn.v_proj.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.o_proj.weight', 'base_model.model.model.layers.11.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.11.mlp.gate_proj.weight', 'base_model.model.model.layers.11.mlp.down_proj.weight', 'base_model.model.model.layers.11.mlp.up_proj.weight', 'base_model.model.model.layers.11.input_layernorm.weight', 'base_model.model.model.layers.11.post_attention_layernorm.weight', 'base_model.model.model.layers.12.self_attn.q_proj.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.weight', 'base_model.model.model.layers.12.self_attn.v_proj.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.o_proj.weight', 'base_model.model.model.layers.12.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.12.mlp.gate_proj.weight', 'base_model.model.model.layers.12.mlp.down_proj.weight', 'base_model.model.model.layers.12.mlp.up_proj.weight', 'base_model.model.model.layers.12.input_layernorm.weight', 'base_model.model.model.layers.12.post_attention_layernorm.weight', 'base_model.model.model.layers.13.self_attn.q_proj.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.weight', 'base_model.model.model.layers.13.self_attn.v_proj.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.o_proj.weight', 'base_model.model.model.layers.13.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.13.mlp.gate_proj.weight', 'base_model.model.model.layers.13.mlp.down_proj.weight', 'base_model.model.model.layers.13.mlp.up_proj.weight', 'base_model.model.model.layers.13.input_layernorm.weight', 'base_model.model.model.layers.13.post_attention_layernorm.weight', 'base_model.model.model.layers.14.self_attn.q_proj.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.weight', 'base_model.model.model.layers.14.self_attn.v_proj.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.o_proj.weight', 'base_model.model.model.layers.14.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.14.mlp.gate_proj.weight', 'base_model.model.model.layers.14.mlp.down_proj.weight', 'base_model.model.model.layers.14.mlp.up_proj.weight', 'base_model.model.model.layers.14.input_layernorm.weight', 'base_model.model.model.layers.14.post_attention_layernorm.weight', 'base_model.model.model.layers.15.self_attn.q_proj.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.weight', 'base_model.model.model.layers.15.self_attn.v_proj.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.weight', 'base_model.model.model.layers.15.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.15.mlp.gate_proj.weight', 'base_model.model.model.layers.15.mlp.down_proj.weight', 'base_model.model.model.layers.15.mlp.up_proj.weight', 'base_model.model.model.layers.15.input_layernorm.weight', 'base_model.model.model.layers.15.post_attention_layernorm.weight', 'base_model.model.model.layers.16.self_attn.q_proj.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.weight', 'base_model.model.model.layers.16.self_attn.v_proj.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.weight', 'base_model.model.model.layers.16.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.16.mlp.gate_proj.weight', 'base_model.model.model.layers.16.mlp.down_proj.weight', 'base_model.model.model.layers.16.mlp.up_proj.weight', 'base_model.model.model.layers.16.input_layernorm.weight', 'base_model.model.model.layers.16.post_attention_layernorm.weight', 'base_model.model.model.layers.17.self_attn.q_proj.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.weight', 'base_model.model.model.layers.17.self_attn.v_proj.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.o_proj.weight', 'base_model.model.model.layers.17.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.17.mlp.gate_proj.weight', 'base_model.model.model.layers.17.mlp.down_proj.weight', 'base_model.model.model.layers.17.mlp.up_proj.weight', 'base_model.model.model.layers.17.input_layernorm.weight', 'base_model.model.model.layers.17.post_attention_layernorm.weight', 'base_model.model.model.layers.18.self_attn.q_proj.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.weight', 'base_model.model.model.layers.18.self_attn.v_proj.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.o_proj.weight', 'base_model.model.model.layers.18.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.18.mlp.gate_proj.weight', 'base_model.model.model.layers.18.mlp.down_proj.weight', 'base_model.model.model.layers.18.mlp.up_proj.weight', 'base_model.model.model.layers.18.input_layernorm.weight', 'base_model.model.model.layers.18.post_attention_layernorm.weight', 'base_model.model.model.layers.19.self_attn.q_proj.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.weight', 'base_model.model.model.layers.19.self_attn.v_proj.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.o_proj.weight', 'base_model.model.model.layers.19.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.19.mlp.gate_proj.weight', 'base_model.model.model.layers.19.mlp.down_proj.weight', 'base_model.model.model.layers.19.mlp.up_proj.weight', 'base_model.model.model.layers.19.input_layernorm.weight', 'base_model.model.model.layers.19.post_attention_layernorm.weight', 'base_model.model.model.layers.20.self_attn.q_proj.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.weight', 'base_model.model.model.layers.20.self_attn.v_proj.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.o_proj.weight', 'base_model.model.model.layers.20.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.20.mlp.gate_proj.weight', 'base_model.model.model.layers.20.mlp.down_proj.weight', 'base_model.model.model.layers.20.mlp.up_proj.weight', 'base_model.model.model.layers.20.input_layernorm.weight', 'base_model.model.model.layers.20.post_attention_layernorm.weight', 'base_model.model.model.layers.21.self_attn.q_proj.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.weight', 'base_model.model.model.layers.21.self_attn.v_proj.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.o_proj.weight', 'base_model.model.model.layers.21.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.21.mlp.gate_proj.weight', 'base_model.model.model.layers.21.mlp.down_proj.weight', 'base_model.model.model.layers.21.mlp.up_proj.weight', 'base_model.model.model.layers.21.input_layernorm.weight', 'base_model.model.model.layers.21.post_attention_layernorm.weight', 'base_model.model.model.layers.22.self_attn.q_proj.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.weight', 'base_model.model.model.layers.22.self_attn.v_proj.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.o_proj.weight', 'base_model.model.model.layers.22.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.22.mlp.gate_proj.weight', 'base_model.model.model.layers.22.mlp.down_proj.weight', 'base_model.model.model.layers.22.mlp.up_proj.weight', 'base_model.model.model.layers.22.input_layernorm.weight', 'base_model.model.model.layers.22.post_attention_layernorm.weight', 'base_model.model.model.layers.23.self_attn.q_proj.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.weight', 'base_model.model.model.layers.23.self_attn.v_proj.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.o_proj.weight', 'base_model.model.model.layers.23.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.23.mlp.gate_proj.weight', 'base_model.model.model.layers.23.mlp.down_proj.weight', 'base_model.model.model.layers.23.mlp.up_proj.weight', 'base_model.model.model.layers.23.input_layernorm.weight', 'base_model.model.model.layers.23.post_attention_layernorm.weight', 'base_model.model.model.layers.24.self_attn.q_proj.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.k_proj.weight', 'base_model.model.model.layers.24.self_attn.v_proj.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.o_proj.weight', 'base_model.model.model.layers.24.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.24.mlp.gate_proj.weight', 'base_model.model.model.layers.24.mlp.down_proj.weight', 'base_model.model.model.layers.24.mlp.up_proj.weight', 'base_model.model.model.layers.24.input_layernorm.weight', 'base_model.model.model.layers.24.post_attention_layernorm.weight', 'base_model.model.model.layers.25.self_attn.q_proj.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.k_proj.weight', 'base_model.model.model.layers.25.self_attn.v_proj.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.o_proj.weight', 'base_model.model.model.layers.25.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.25.mlp.gate_proj.weight', 'base_model.model.model.layers.25.mlp.down_proj.weight', 'base_model.model.model.layers.25.mlp.up_proj.weight', 'base_model.model.model.layers.25.input_layernorm.weight', 'base_model.model.model.layers.25.post_attention_layernorm.weight', 'base_model.model.model.layers.26.self_attn.q_proj.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.k_proj.weight', 'base_model.model.model.layers.26.self_attn.v_proj.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.o_proj.weight', 'base_model.model.model.layers.26.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.26.mlp.gate_proj.weight', 'base_model.model.model.layers.26.mlp.down_proj.weight', 'base_model.model.model.layers.26.mlp.up_proj.weight', 'base_model.model.model.layers.26.input_layernorm.weight', 'base_model.model.model.layers.26.post_attention_layernorm.weight', 'base_model.model.model.layers.27.self_attn.q_proj.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.k_proj.weight', 'base_model.model.model.layers.27.self_attn.v_proj.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.o_proj.weight', 'base_model.model.model.layers.27.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.27.mlp.gate_proj.weight', 'base_model.model.model.layers.27.mlp.down_proj.weight', 'base_model.model.model.layers.27.mlp.up_proj.weight', 'base_model.model.model.layers.27.input_layernorm.weight', 'base_model.model.model.layers.27.post_attention_layernorm.weight', 'base_model.model.model.layers.28.self_attn.q_proj.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.k_proj.weight', 'base_model.model.model.layers.28.self_attn.v_proj.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.o_proj.weight', 'base_model.model.model.layers.28.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.28.mlp.gate_proj.weight', 'base_model.model.model.layers.28.mlp.down_proj.weight', 'base_model.model.model.layers.28.mlp.up_proj.weight', 'base_model.model.model.layers.28.input_layernorm.weight', 'base_model.model.model.layers.28.post_attention_layernorm.weight', 'base_model.model.model.layers.29.self_attn.q_proj.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.k_proj.weight', 'base_model.model.model.layers.29.self_attn.v_proj.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.o_proj.weight', 'base_model.model.model.layers.29.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.29.mlp.gate_proj.weight', 'base_model.model.model.layers.29.mlp.down_proj.weight', 'base_model.model.model.layers.29.mlp.up_proj.weight', 'base_model.model.model.layers.29.input_layernorm.weight', 'base_model.model.model.layers.29.post_attention_layernorm.weight', 'base_model.model.model.layers.30.self_attn.q_proj.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.k_proj.weight', 'base_model.model.model.layers.30.self_attn.v_proj.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.o_proj.weight', 'base_model.model.model.layers.30.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.30.mlp.gate_proj.weight', 'base_model.model.model.layers.30.mlp.down_proj.weight', 'base_model.model.model.layers.30.mlp.up_proj.weight', 'base_model.model.model.layers.30.input_layernorm.weight', 'base_model.model.model.layers.30.post_attention_layernorm.weight', 'base_model.model.model.layers.31.self_attn.q_proj.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.k_proj.weight', 'base_model.model.model.layers.31.self_attn.v_proj.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.o_proj.weight', 'base_model.model.model.layers.31.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.31.mlp.gate_proj.weight', 'base_model.model.model.layers.31.mlp.down_proj.weight', 'base_model.model.model.layers.31.mlp.up_proj.weight', 'base_model.model.model.layers.31.input_layernorm.weight', 'base_model.model.model.layers.31.post_attention_layernorm.weight', 'base_model.model.model.norm.weight', 'base_model.model.lm_head.weight'].\n",
      "There were unexpected keys in the checkpoint model loaded: ['base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_B.weight'].\n"
     ]
    }
   ],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    args=training_arguments,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "model.config.use_cache = False\n",
    "old_state_dict = model.state_dict\n",
    "model.state_dict = (\n",
    "    lambda self, *_, **__: get_peft_model_state_dict(\n",
    "        self, old_state_dict()\n",
    "    )\n",
    ").__get__(model, type(model))\n",
    " \n",
    "model = torch.compile(model)\n",
    " \n",
    "trainer.train()\n",
    "model.save_pretrained(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7dbda8a-4907-49dd-af4f-1ff376078e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function get_peft_model_state_dict in module peft.utils.save_and_load:\n",
      "\n",
      "get_peft_model_state_dict(model, state_dict=None, adapter_name='default')\n",
      "    Get the state dict of the Peft model.\n",
      "    \n",
      "    Args:\n",
      "        model ([`PeftModel`]): The Peft model. When using torch.nn.DistributedDataParallel, DeepSpeed or FSDP,\n",
      "        the model should be the underlying model/unwrapped model (i.e. model.module).\n",
      "        state_dict (`dict`, *optional*, defaults to `None`):\n",
      "            The state dict of the model. If not provided, the state dict of the model\n",
      "        will be used.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(get_peft_model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b0b55e9-9f2d-43c0-85e6-d005a41a719c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OptimizedModule(\n",
       "  (_orig_mod): PeftModelForCausalLM(\n",
       "    (base_model): LoraModel(\n",
       "      (model): LlamaForCausalLM(\n",
       "        (model): LlamaModel(\n",
       "          (embed_tokens): Embedding(32000, 4096, padding_idx=31999)\n",
       "          (layers): ModuleList(\n",
       "            (0-31): 32 x LlamaDecoderLayer(\n",
       "              (self_attn): LlamaAttention(\n",
       "                (q_proj): Linear8bitLt(\n",
       "                  in_features=4096, out_features=4096, bias=False\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "                (v_proj): Linear8bitLt(\n",
       "                  in_features=4096, out_features=4096, bias=False\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "                (rotary_emb): LlamaRotaryEmbedding()\n",
       "              )\n",
       "              (mlp): LlamaMLP(\n",
       "                (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "                (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "                (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "                (act_fn): SiLUActivation()\n",
       "              )\n",
       "              (input_layernorm): LlamaRMSNorm()\n",
       "              (post_attention_layernorm): LlamaRMSNorm()\n",
       "            )\n",
       "          )\n",
       "          (norm): LlamaRMSNorm()\n",
       "        )\n",
       "        (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "25a82ce4-c37b-4338-8238-3a5433870fa9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Does Salerno win?',\n",
       " 'input': 'The 1984 Bail Reform Act allowed the federal courts to detain an arrestee prior to trial if the government could prove that the individual was potentially dangerous to other people in the community. Prosecutors alleged that Salerno and another person in this case were prominent figures in the La Cosa Nostra crime family.\\n',\n",
       " 'ID': 'TEST_0000',\n",
       " 'is_first_in': 1,\n",
       " 'party': 'Salerno'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('test_json.pickle', 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "dataset = dataset[\"root\"]\n",
    "\n",
    "dataset = [\n",
    "    {\n",
    "        'instruction' : x['prompt'],\n",
    "        'input' : x['input'],\n",
    "        \"ID\" : x[\"ID\"],\n",
    "        \"is_first_in\" : x[\"is_first_in\"],\n",
    "        'party' : x['party']\n",
    "#         'output' : x['answer']\n",
    "    }\n",
    "    for x in dataset\n",
    "]\n",
    "\n",
    "dataset = sorted(dataset, key=lambda x:x[\"ID\"], reverse=False)\n",
    "dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1e4ac69-907f-4a70-9005-73445761f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig\n",
    "from transformers.generation.utils import GreedySearchDecoderOnlyOutput\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b695346-4a49-44b3-8a03-4b6c52caed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_prompt(instruction: str) -> str:\n",
    "#     return PROMPT_TEMPLATE.replace(\"[INSTRUCTION]\", instruction)\n",
    "def create_prompt(data_point):\n",
    "    return f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.  # noqa: E501\n",
    "### Instruction:\n",
    "{data_point[\"instruction\"]}\n",
    "### Input:\n",
    "{data_point[\"input\"]}\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0289121-3d2d-4b10-8043-f07ad968b509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt: str, model: model):\n",
    "    encoding = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = encoding[\"input_ids\"].to(DEVICE)\n",
    " \n",
    "    generation_config = GenerationConfig(\n",
    "        temperature=0.1,\n",
    "        top_p=0.75,\n",
    "        repetition_penalty=1.1,\n",
    "    )\n",
    "    with torch.inference_mode():\n",
    "        return model.generate(\n",
    "            input_ids=input_ids,\n",
    "            generation_config=generation_config,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "            max_new_tokens=1,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6788a842-ae8b-4a98-a886-d702dd1e9f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_response(response) -> str:\n",
    "    decoded_output = tokenizer.decode(response.sequences[0])\n",
    "    response = decoded_output.split(\"### Response:\")[1].strip()\n",
    "    return \"\\n\".join(textwrap.wrap(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0e458cb-9858-45f1-abba-49c50678e8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_alpaca(prompt, model: model) -> str:\n",
    "    prompt = create_prompt(prompt)\n",
    "    response = generate_response(prompt, model)\n",
    "    response = format_response(response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72420e5-3d77-4b62-b6c6-fdaa2b1a3df7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fae5fdcc-9b32-41d0-9b78-4f873e1ce599",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "473746de-5407-4d93-855b-58a37324440d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1240/1240 [10:16<00:00,  2.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('TEST_0000', 1),\n",
       " ('TEST_0001', 1),\n",
       " ('TEST_0002', 1),\n",
       " ('TEST_0003', 1),\n",
       " ('TEST_0004', 1),\n",
       " ('TEST_0005', 1),\n",
       " ('TEST_0006', 1),\n",
       " ('TEST_0007', 0),\n",
       " ('TEST_0008', 0),\n",
       " ('TEST_0009', 1),\n",
       " ('TEST_0010', 1),\n",
       " ('TEST_0011', 1),\n",
       " ('TEST_0012', 1),\n",
       " ('TEST_0013', 1),\n",
       " ('TEST_0014', 1),\n",
       " ('TEST_0015', 1),\n",
       " ('TEST_0016', 1),\n",
       " ('TEST_0017', 0),\n",
       " ('TEST_0018', 1),\n",
       " ('TEST_0019', 1),\n",
       " ('TEST_0020', 1),\n",
       " ('TEST_0021', 0),\n",
       " ('TEST_0022', 1),\n",
       " ('TEST_0023', 1),\n",
       " ('TEST_0024', 1),\n",
       " ('TEST_0025', 0),\n",
       " ('TEST_0026', 1),\n",
       " ('TEST_0027', 1),\n",
       " ('TEST_0028', 1),\n",
       " ('TEST_0029', 1),\n",
       " ('TEST_0030', 1),\n",
       " ('TEST_0031', 1),\n",
       " ('TEST_0032', 1),\n",
       " ('TEST_0033', 1),\n",
       " ('TEST_0034', 0),\n",
       " ('TEST_0035', 1),\n",
       " ('TEST_0036', 1),\n",
       " ('TEST_0037', 1),\n",
       " ('TEST_0038', 0),\n",
       " ('TEST_0039', 0),\n",
       " ('TEST_0040', 0),\n",
       " ('TEST_0041', 1),\n",
       " ('TEST_0042', 0),\n",
       " ('TEST_0043', 0),\n",
       " ('TEST_0044', 1),\n",
       " ('TEST_0045', 1),\n",
       " ('TEST_0046', 1),\n",
       " ('TEST_0047', 1),\n",
       " ('TEST_0048', 0),\n",
       " ('TEST_0049', 0),\n",
       " ('TEST_0050', 0),\n",
       " ('TEST_0051', 1),\n",
       " ('TEST_0052', 1),\n",
       " ('TEST_0053', 1),\n",
       " ('TEST_0054', 0),\n",
       " ('TEST_0055', 1),\n",
       " ('TEST_0056', 1),\n",
       " ('TEST_0057', 0),\n",
       " ('TEST_0058', 1),\n",
       " ('TEST_0059', 1),\n",
       " ('TEST_0060', 0),\n",
       " ('TEST_0061', 1),\n",
       " ('TEST_0062', 1),\n",
       " ('TEST_0063', 1),\n",
       " ('TEST_0064', 0),\n",
       " ('TEST_0065', 1),\n",
       " ('TEST_0066', 0),\n",
       " ('TEST_0067', 0),\n",
       " ('TEST_0068', 0),\n",
       " ('TEST_0069', 1),\n",
       " ('TEST_0070', 1),\n",
       " ('TEST_0071', 1),\n",
       " ('TEST_0072', 1),\n",
       " ('TEST_0073', 1),\n",
       " ('TEST_0074', 1),\n",
       " ('TEST_0075', 1),\n",
       " ('TEST_0076', 0),\n",
       " ('TEST_0077', 0),\n",
       " ('TEST_0078', 1),\n",
       " ('TEST_0079', 0),\n",
       " ('TEST_0080', 1),\n",
       " ('TEST_0081', 1),\n",
       " ('TEST_0082', 1),\n",
       " ('TEST_0083', 1),\n",
       " ('TEST_0084', 1),\n",
       " ('TEST_0085', 0),\n",
       " ('TEST_0086', 1),\n",
       " ('TEST_0087', 1),\n",
       " ('TEST_0088', 1),\n",
       " ('TEST_0089', 0),\n",
       " ('TEST_0090', 1),\n",
       " ('TEST_0091', 0),\n",
       " ('TEST_0092', 1),\n",
       " ('TEST_0093', 0),\n",
       " ('TEST_0094', 1),\n",
       " ('TEST_0095', 1),\n",
       " ('TEST_0096', 1),\n",
       " ('TEST_0097', 1),\n",
       " ('TEST_0098', 1),\n",
       " ('TEST_0099', 1),\n",
       " ('TEST_0100', 1),\n",
       " ('TEST_0101', 1),\n",
       " ('TEST_0102', 0),\n",
       " ('TEST_0103', 1),\n",
       " ('TEST_0104', 1),\n",
       " ('TEST_0105', 1),\n",
       " ('TEST_0106', 1),\n",
       " ('TEST_0107', 1),\n",
       " ('TEST_0108', 1),\n",
       " ('TEST_0109', 1),\n",
       " ('TEST_0110', 0),\n",
       " ('TEST_0111', 0),\n",
       " ('TEST_0112', 1),\n",
       " ('TEST_0113', 0),\n",
       " ('TEST_0114', 1),\n",
       " ('TEST_0115', 1),\n",
       " ('TEST_0116', 1),\n",
       " ('TEST_0117', 1),\n",
       " ('TEST_0118', 1),\n",
       " ('TEST_0119', 1),\n",
       " ('TEST_0120', 1),\n",
       " ('TEST_0121', 1),\n",
       " ('TEST_0122', 1),\n",
       " ('TEST_0123', 0),\n",
       " ('TEST_0124', 1),\n",
       " ('TEST_0125', 0),\n",
       " ('TEST_0126', 1),\n",
       " ('TEST_0127', 1),\n",
       " ('TEST_0128', 1),\n",
       " ('TEST_0129', 1),\n",
       " ('TEST_0130', 0),\n",
       " ('TEST_0131', 1),\n",
       " ('TEST_0132', 1),\n",
       " ('TEST_0133', 1),\n",
       " ('TEST_0134', 1),\n",
       " ('TEST_0135', 1),\n",
       " ('TEST_0136', 0),\n",
       " ('TEST_0137', 1),\n",
       " ('TEST_0138', 1),\n",
       " ('TEST_0139', 1),\n",
       " ('TEST_0140', 1),\n",
       " ('TEST_0141', 1),\n",
       " ('TEST_0142', 1),\n",
       " ('TEST_0143', 1),\n",
       " ('TEST_0144', 0),\n",
       " ('TEST_0145', 0),\n",
       " ('TEST_0146', 0),\n",
       " ('TEST_0147', 1),\n",
       " ('TEST_0148', 1),\n",
       " ('TEST_0149', 0),\n",
       " ('TEST_0150', 1),\n",
       " ('TEST_0151', 1),\n",
       " ('TEST_0152', 1),\n",
       " ('TEST_0153', 1),\n",
       " ('TEST_0154', 1),\n",
       " ('TEST_0155', 1),\n",
       " ('TEST_0156', 0),\n",
       " ('TEST_0157', 1),\n",
       " ('TEST_0158', 0),\n",
       " ('TEST_0159', 1),\n",
       " ('TEST_0160', 0),\n",
       " ('TEST_0161', 1),\n",
       " ('TEST_0162', 0),\n",
       " ('TEST_0163', 1),\n",
       " ('TEST_0164', 1),\n",
       " ('TEST_0165', 1),\n",
       " ('TEST_0166', 1),\n",
       " ('TEST_0167', 1),\n",
       " ('TEST_0168', 1),\n",
       " ('TEST_0169', 1),\n",
       " ('TEST_0170', 0),\n",
       " ('TEST_0171', 1),\n",
       " ('TEST_0172', 0),\n",
       " ('TEST_0173', 1),\n",
       " ('TEST_0174', 1),\n",
       " ('TEST_0175', 0),\n",
       " ('TEST_0176', 1),\n",
       " ('TEST_0177', 1),\n",
       " ('TEST_0178', 1),\n",
       " ('TEST_0179', 0),\n",
       " ('TEST_0180', 1),\n",
       " ('TEST_0181', 0),\n",
       " ('TEST_0182', 1),\n",
       " ('TEST_0183', 0),\n",
       " ('TEST_0184', 0),\n",
       " ('TEST_0185', 1),\n",
       " ('TEST_0186', 1),\n",
       " ('TEST_0187', 1),\n",
       " ('TEST_0188', 1),\n",
       " ('TEST_0189', 1),\n",
       " ('TEST_0190', 0),\n",
       " ('TEST_0191', 1),\n",
       " ('TEST_0192', 1),\n",
       " ('TEST_0193', 1),\n",
       " ('TEST_0194', 1),\n",
       " ('TEST_0195', 1),\n",
       " ('TEST_0196', 1),\n",
       " ('TEST_0197', 1),\n",
       " ('TEST_0198', 1),\n",
       " ('TEST_0199', 0),\n",
       " ('TEST_0200', 0),\n",
       " ('TEST_0201', 1),\n",
       " ('TEST_0202', 1),\n",
       " ('TEST_0203', 1),\n",
       " ('TEST_0204', 1),\n",
       " ('TEST_0205', 0),\n",
       " ('TEST_0206', 1),\n",
       " ('TEST_0207', 0),\n",
       " ('TEST_0208', 1),\n",
       " ('TEST_0209', 1),\n",
       " ('TEST_0210', 1),\n",
       " ('TEST_0211', 0),\n",
       " ('TEST_0212', 1),\n",
       " ('TEST_0213', 1),\n",
       " ('TEST_0214', 1),\n",
       " ('TEST_0215', 1),\n",
       " ('TEST_0216', 1),\n",
       " ('TEST_0217', 1),\n",
       " ('TEST_0218', 1),\n",
       " ('TEST_0219', 0),\n",
       " ('TEST_0220', 0),\n",
       " ('TEST_0221', 0),\n",
       " ('TEST_0222', 1),\n",
       " ('TEST_0223', 1),\n",
       " ('TEST_0224', 1),\n",
       " ('TEST_0225', 1),\n",
       " ('TEST_0226', 1),\n",
       " ('TEST_0227', 1),\n",
       " ('TEST_0228', 1),\n",
       " ('TEST_0229', 1),\n",
       " ('TEST_0230', 1),\n",
       " ('TEST_0231', 1),\n",
       " ('TEST_0232', 0),\n",
       " ('TEST_0233', 1),\n",
       " ('TEST_0234', 0),\n",
       " ('TEST_0235', 1),\n",
       " ('TEST_0236', 1),\n",
       " ('TEST_0237', 1),\n",
       " ('TEST_0238', 0),\n",
       " ('TEST_0239', 1),\n",
       " ('TEST_0240', 1),\n",
       " ('TEST_0241', 1),\n",
       " ('TEST_0242', 1),\n",
       " ('TEST_0243', 0),\n",
       " ('TEST_0244', 0),\n",
       " ('TEST_0245', 0),\n",
       " ('TEST_0246', 1),\n",
       " ('TEST_0247', 1),\n",
       " ('TEST_0248', 1),\n",
       " ('TEST_0249', 1),\n",
       " ('TEST_0250', 1),\n",
       " ('TEST_0251', 0),\n",
       " ('TEST_0252', 1),\n",
       " ('TEST_0253', 1),\n",
       " ('TEST_0254', 0),\n",
       " ('TEST_0255', 1),\n",
       " ('TEST_0256', 1),\n",
       " ('TEST_0257', 1),\n",
       " ('TEST_0258', 1),\n",
       " ('TEST_0259', 1),\n",
       " ('TEST_0260', 1),\n",
       " ('TEST_0261', 1),\n",
       " ('TEST_0262', 1),\n",
       " ('TEST_0263', 1),\n",
       " ('TEST_0264', 1),\n",
       " ('TEST_0265', 0),\n",
       " ('TEST_0266', 0),\n",
       " ('TEST_0267', 1),\n",
       " ('TEST_0268', 1),\n",
       " ('TEST_0269', 1),\n",
       " ('TEST_0270', 0),\n",
       " ('TEST_0271', 1),\n",
       " ('TEST_0272', 1),\n",
       " ('TEST_0273', 1),\n",
       " ('TEST_0274', 1),\n",
       " ('TEST_0275', 1),\n",
       " ('TEST_0276', 1),\n",
       " ('TEST_0277', 1),\n",
       " ('TEST_0278', 1),\n",
       " ('TEST_0279', 0),\n",
       " ('TEST_0280', 1),\n",
       " ('TEST_0281', 1),\n",
       " ('TEST_0282', 0),\n",
       " ('TEST_0283', 1),\n",
       " ('TEST_0284', 1),\n",
       " ('TEST_0285', 1),\n",
       " ('TEST_0286', 0),\n",
       " ('TEST_0287', 1),\n",
       " ('TEST_0288', 1),\n",
       " ('TEST_0289', 1),\n",
       " ('TEST_0290', 0),\n",
       " ('TEST_0291', 0),\n",
       " ('TEST_0292', 1),\n",
       " ('TEST_0293', 1),\n",
       " ('TEST_0294', 0),\n",
       " ('TEST_0295', 0),\n",
       " ('TEST_0296', 0),\n",
       " ('TEST_0297', 1),\n",
       " ('TEST_0298', 0),\n",
       " ('TEST_0299', 0),\n",
       " ('TEST_0300', 1),\n",
       " ('TEST_0301', 1),\n",
       " ('TEST_0302', 1),\n",
       " ('TEST_0303', 1),\n",
       " ('TEST_0304', 1),\n",
       " ('TEST_0305', 1),\n",
       " ('TEST_0306', 1),\n",
       " ('TEST_0307', 1),\n",
       " ('TEST_0308', 1),\n",
       " ('TEST_0309', 1),\n",
       " ('TEST_0310', 0),\n",
       " ('TEST_0311', 1),\n",
       " ('TEST_0312', 1),\n",
       " ('TEST_0313', 1),\n",
       " ('TEST_0314', 1),\n",
       " ('TEST_0315', 1),\n",
       " ('TEST_0316', 1),\n",
       " ('TEST_0317', 0),\n",
       " ('TEST_0318', 1),\n",
       " ('TEST_0319', 1),\n",
       " ('TEST_0320', 0),\n",
       " ('TEST_0321', 1),\n",
       " ('TEST_0322', 1),\n",
       " ('TEST_0323', 1),\n",
       " ('TEST_0324', 0),\n",
       " ('TEST_0325', 1),\n",
       " ('TEST_0326', 0),\n",
       " ('TEST_0327', 0),\n",
       " ('TEST_0328', 1),\n",
       " ('TEST_0329', 0),\n",
       " ('TEST_0330', 1),\n",
       " ('TEST_0331', 0),\n",
       " ('TEST_0332', 0),\n",
       " ('TEST_0333', 1),\n",
       " ('TEST_0334', 0),\n",
       " ('TEST_0335', 1),\n",
       " ('TEST_0336', 0),\n",
       " ('TEST_0337', 1),\n",
       " ('TEST_0338', 0),\n",
       " ('TEST_0339', 1),\n",
       " ('TEST_0340', 1),\n",
       " ('TEST_0341', 0),\n",
       " ('TEST_0342', 1),\n",
       " ('TEST_0343', 1),\n",
       " ('TEST_0344', 1),\n",
       " ('TEST_0345', 1),\n",
       " ('TEST_0346', 0),\n",
       " ('TEST_0347', 1),\n",
       " ('TEST_0348', 1),\n",
       " ('TEST_0349', 1),\n",
       " ('TEST_0350', 1),\n",
       " ('TEST_0351', 1),\n",
       " ('TEST_0352', 0),\n",
       " ('TEST_0353', 1),\n",
       " ('TEST_0354', 0),\n",
       " ('TEST_0355', 0),\n",
       " ('TEST_0356', 1),\n",
       " ('TEST_0357', 1),\n",
       " ('TEST_0358', 1),\n",
       " ('TEST_0359', 0),\n",
       " ('TEST_0360', 1),\n",
       " ('TEST_0361', 0),\n",
       " ('TEST_0362', 0),\n",
       " ('TEST_0363', 1),\n",
       " ('TEST_0364', 0),\n",
       " ('TEST_0365', 0),\n",
       " ('TEST_0366', 0),\n",
       " ('TEST_0367', 1),\n",
       " ('TEST_0368', 1),\n",
       " ('TEST_0369', 0),\n",
       " ('TEST_0370', 1),\n",
       " ('TEST_0371', 1),\n",
       " ('TEST_0372', 0),\n",
       " ('TEST_0373', 1),\n",
       " ('TEST_0374', 1),\n",
       " ('TEST_0375', 1),\n",
       " ('TEST_0376', 0),\n",
       " ('TEST_0377', 1),\n",
       " ('TEST_0378', 1),\n",
       " ('TEST_0379', 1),\n",
       " ('TEST_0380', 0),\n",
       " ('TEST_0381', 1),\n",
       " ('TEST_0382', 1),\n",
       " ('TEST_0383', 1),\n",
       " ('TEST_0384', 1),\n",
       " ('TEST_0385', 1),\n",
       " ('TEST_0386', 1),\n",
       " ('TEST_0387', 0),\n",
       " ('TEST_0388', 0),\n",
       " ('TEST_0389', 1),\n",
       " ('TEST_0390', 1),\n",
       " ('TEST_0391', 0),\n",
       " ('TEST_0392', 1),\n",
       " ('TEST_0393', 1),\n",
       " ('TEST_0394', 1),\n",
       " ('TEST_0395', 0),\n",
       " ('TEST_0396', 0),\n",
       " ('TEST_0397', 1),\n",
       " ('TEST_0398', 0),\n",
       " ('TEST_0399', 1),\n",
       " ('TEST_0400', 0),\n",
       " ('TEST_0401', 0),\n",
       " ('TEST_0402', 0),\n",
       " ('TEST_0403', 0),\n",
       " ('TEST_0404', 1),\n",
       " ('TEST_0405', 1),\n",
       " ('TEST_0406', 0),\n",
       " ('TEST_0407', 1),\n",
       " ('TEST_0408', 1),\n",
       " ('TEST_0409', 0),\n",
       " ('TEST_0410', 1),\n",
       " ('TEST_0411', 1),\n",
       " ('TEST_0412', 0),\n",
       " ('TEST_0413', 1),\n",
       " ('TEST_0414', 1),\n",
       " ('TEST_0415', 1),\n",
       " ('TEST_0416', 1),\n",
       " ('TEST_0417', 1),\n",
       " ('TEST_0418', 1),\n",
       " ('TEST_0419', 1),\n",
       " ('TEST_0420', 1),\n",
       " ('TEST_0421', 1),\n",
       " ('TEST_0422', 1),\n",
       " ('TEST_0423', 0),\n",
       " ('TEST_0424', 1),\n",
       " ('TEST_0425', 1),\n",
       " ('TEST_0426', 1),\n",
       " ('TEST_0427', 1),\n",
       " ('TEST_0428', 0),\n",
       " ('TEST_0429', 0),\n",
       " ('TEST_0430', 1),\n",
       " ('TEST_0431', 1),\n",
       " ('TEST_0432', 1),\n",
       " ('TEST_0433', 1),\n",
       " ('TEST_0434', 1),\n",
       " ('TEST_0435', 1),\n",
       " ('TEST_0436', 1),\n",
       " ('TEST_0437', 1),\n",
       " ('TEST_0438', 0),\n",
       " ('TEST_0439', 1),\n",
       " ('TEST_0440', 1),\n",
       " ('TEST_0441', 0),\n",
       " ('TEST_0442', 1),\n",
       " ('TEST_0443', 1),\n",
       " ('TEST_0444', 1),\n",
       " ('TEST_0445', 1),\n",
       " ('TEST_0446', 0),\n",
       " ('TEST_0447', 1),\n",
       " ('TEST_0448', 1),\n",
       " ('TEST_0449', 1),\n",
       " ('TEST_0450', 1),\n",
       " ('TEST_0451', 1),\n",
       " ('TEST_0452', 0),\n",
       " ('TEST_0453', 0),\n",
       " ('TEST_0454', 0),\n",
       " ('TEST_0455', 1),\n",
       " ('TEST_0456', 0),\n",
       " ('TEST_0457', 1),\n",
       " ('TEST_0458', 1),\n",
       " ('TEST_0459', 1),\n",
       " ('TEST_0460', 1),\n",
       " ('TEST_0461', 1),\n",
       " ('TEST_0462', 1),\n",
       " ('TEST_0463', 1),\n",
       " ('TEST_0464', 0),\n",
       " ('TEST_0465', 1),\n",
       " ('TEST_0466', 1),\n",
       " ('TEST_0467', 1),\n",
       " ('TEST_0468', 1),\n",
       " ('TEST_0469', 1),\n",
       " ('TEST_0470', 1),\n",
       " ('TEST_0471', 1),\n",
       " ('TEST_0472', 1),\n",
       " ('TEST_0473', 1),\n",
       " ('TEST_0474', 0),\n",
       " ('TEST_0475', 1),\n",
       " ('TEST_0476', 0),\n",
       " ('TEST_0477', 0),\n",
       " ('TEST_0478', 0),\n",
       " ('TEST_0479', 1),\n",
       " ('TEST_0480', 1),\n",
       " ('TEST_0481', 1),\n",
       " ('TEST_0482', 0),\n",
       " ('TEST_0483', 1),\n",
       " ('TEST_0484', 0),\n",
       " ('TEST_0485', 0),\n",
       " ('TEST_0486', 1),\n",
       " ('TEST_0487', 0),\n",
       " ('TEST_0488', 1),\n",
       " ('TEST_0489', 0),\n",
       " ('TEST_0490', 1),\n",
       " ('TEST_0491', 0),\n",
       " ('TEST_0492', 1),\n",
       " ('TEST_0493', 1),\n",
       " ('TEST_0494', 1),\n",
       " ('TEST_0495', 1),\n",
       " ('TEST_0496', 1),\n",
       " ('TEST_0497', 1),\n",
       " ('TEST_0498', 0),\n",
       " ('TEST_0499', 0),\n",
       " ('TEST_0500', 1),\n",
       " ('TEST_0501', 1),\n",
       " ('TEST_0502', 1),\n",
       " ('TEST_0503', 0),\n",
       " ('TEST_0504', 1),\n",
       " ('TEST_0505', 1),\n",
       " ('TEST_0506', 0),\n",
       " ('TEST_0507', 1),\n",
       " ('TEST_0508', 1),\n",
       " ('TEST_0509', 1),\n",
       " ('TEST_0510', 1),\n",
       " ('TEST_0511', 0),\n",
       " ('TEST_0512', 1),\n",
       " ('TEST_0513', 0),\n",
       " ('TEST_0514', 1),\n",
       " ('TEST_0515', 1),\n",
       " ('TEST_0516', 1),\n",
       " ('TEST_0517', 0),\n",
       " ('TEST_0518', 1),\n",
       " ('TEST_0519', 1),\n",
       " ('TEST_0520', 0),\n",
       " ('TEST_0521', 0),\n",
       " ('TEST_0522', 1),\n",
       " ('TEST_0523', 0),\n",
       " ('TEST_0524', 1),\n",
       " ('TEST_0525', 0),\n",
       " ('TEST_0526', 1),\n",
       " ('TEST_0527', 1),\n",
       " ('TEST_0528', 1),\n",
       " ('TEST_0529', 0),\n",
       " ('TEST_0530', 1),\n",
       " ('TEST_0531', 1),\n",
       " ('TEST_0532', 1),\n",
       " ('TEST_0533', 0),\n",
       " ('TEST_0534', 1),\n",
       " ('TEST_0535', 1),\n",
       " ('TEST_0536', 0),\n",
       " ('TEST_0537', 1),\n",
       " ('TEST_0538', 1),\n",
       " ('TEST_0539', 0),\n",
       " ('TEST_0540', 0),\n",
       " ('TEST_0541', 1),\n",
       " ('TEST_0542', 0),\n",
       " ('TEST_0543', 1),\n",
       " ('TEST_0544', 0),\n",
       " ('TEST_0545', 1),\n",
       " ('TEST_0546', 1),\n",
       " ('TEST_0547', 1),\n",
       " ('TEST_0548', 0),\n",
       " ('TEST_0549', 1),\n",
       " ('TEST_0550', 0),\n",
       " ('TEST_0551', 1),\n",
       " ('TEST_0552', 1),\n",
       " ('TEST_0553', 0),\n",
       " ('TEST_0554', 0),\n",
       " ('TEST_0555', 1),\n",
       " ('TEST_0556', 0),\n",
       " ('TEST_0557', 0),\n",
       " ('TEST_0558', 1),\n",
       " ('TEST_0559', 0),\n",
       " ('TEST_0560', 1),\n",
       " ('TEST_0561', 1),\n",
       " ('TEST_0562', 1),\n",
       " ('TEST_0563', 1),\n",
       " ('TEST_0564', 1),\n",
       " ('TEST_0565', 1),\n",
       " ('TEST_0566', 1),\n",
       " ('TEST_0567', 1),\n",
       " ('TEST_0568', 1),\n",
       " ('TEST_0569', 1),\n",
       " ('TEST_0570', 1),\n",
       " ('TEST_0571', 0),\n",
       " ('TEST_0572', 1),\n",
       " ('TEST_0573', 1),\n",
       " ('TEST_0574', 1),\n",
       " ('TEST_0575', 1),\n",
       " ('TEST_0576', 0),\n",
       " ('TEST_0577', 0),\n",
       " ('TEST_0578', 1),\n",
       " ('TEST_0579', 1),\n",
       " ('TEST_0580', 0),\n",
       " ('TEST_0581', 0),\n",
       " ('TEST_0582', 1),\n",
       " ('TEST_0583', 1),\n",
       " ('TEST_0584', 1),\n",
       " ('TEST_0585', 0),\n",
       " ('TEST_0586', 1),\n",
       " ('TEST_0587', 0),\n",
       " ('TEST_0588', 1),\n",
       " ('TEST_0589', 1),\n",
       " ('TEST_0590', 1),\n",
       " ('TEST_0591', 1),\n",
       " ('TEST_0592', 1),\n",
       " ('TEST_0593', 1),\n",
       " ('TEST_0594', 1),\n",
       " ('TEST_0595', 1),\n",
       " ('TEST_0596', 1),\n",
       " ('TEST_0597', 1),\n",
       " ('TEST_0598', 1),\n",
       " ('TEST_0599', 1),\n",
       " ('TEST_0600', 0),\n",
       " ('TEST_0601', 0),\n",
       " ('TEST_0602', 0),\n",
       " ('TEST_0603', 1),\n",
       " ('TEST_0604', 1),\n",
       " ('TEST_0605', 1),\n",
       " ('TEST_0606', 1),\n",
       " ('TEST_0607', 1),\n",
       " ('TEST_0608', 1),\n",
       " ('TEST_0609', 1),\n",
       " ('TEST_0610', 1),\n",
       " ('TEST_0611', 1),\n",
       " ('TEST_0612', 0),\n",
       " ('TEST_0613', 0),\n",
       " ('TEST_0614', 0),\n",
       " ('TEST_0615', 1),\n",
       " ('TEST_0616', 0),\n",
       " ('TEST_0617', 1),\n",
       " ('TEST_0618', 1),\n",
       " ('TEST_0619', 1),\n",
       " ('TEST_0620', 0),\n",
       " ('TEST_0621', 1),\n",
       " ('TEST_0622', 1),\n",
       " ('TEST_0623', 1),\n",
       " ('TEST_0624', 1),\n",
       " ('TEST_0625', 1),\n",
       " ('TEST_0626', 1),\n",
       " ('TEST_0627', 0),\n",
       " ('TEST_0628', 1),\n",
       " ('TEST_0629', 0),\n",
       " ('TEST_0630', 0),\n",
       " ('TEST_0631', 0),\n",
       " ('TEST_0632', 1),\n",
       " ('TEST_0633', 1),\n",
       " ('TEST_0634', 1),\n",
       " ('TEST_0635', 0),\n",
       " ('TEST_0636', 1),\n",
       " ('TEST_0637', 1),\n",
       " ('TEST_0638', 1),\n",
       " ('TEST_0639', 0),\n",
       " ('TEST_0640', 1),\n",
       " ('TEST_0641', 1),\n",
       " ('TEST_0642', 1),\n",
       " ('TEST_0643', 0),\n",
       " ('TEST_0644', 0),\n",
       " ('TEST_0645', 1),\n",
       " ('TEST_0646', 0),\n",
       " ('TEST_0647', 0),\n",
       " ('TEST_0648', 1),\n",
       " ('TEST_0649', 1),\n",
       " ('TEST_0650', 0),\n",
       " ('TEST_0651', 1),\n",
       " ('TEST_0652', 0),\n",
       " ('TEST_0653', 0),\n",
       " ('TEST_0654', 1),\n",
       " ('TEST_0655', 1),\n",
       " ('TEST_0656', 1),\n",
       " ('TEST_0657', 1),\n",
       " ('TEST_0658', 0),\n",
       " ('TEST_0659', 1),\n",
       " ('TEST_0660', 1),\n",
       " ('TEST_0661', 1),\n",
       " ('TEST_0662', 0),\n",
       " ('TEST_0663', 1),\n",
       " ('TEST_0664', 0),\n",
       " ('TEST_0665', 0),\n",
       " ('TEST_0666', 0),\n",
       " ('TEST_0667', 0),\n",
       " ('TEST_0668', 1),\n",
       " ('TEST_0669', 1),\n",
       " ('TEST_0670', 0),\n",
       " ('TEST_0671', 1),\n",
       " ('TEST_0672', 0),\n",
       " ('TEST_0673', 1),\n",
       " ('TEST_0674', 1),\n",
       " ('TEST_0675', 0),\n",
       " ('TEST_0676', 0),\n",
       " ('TEST_0677', 1),\n",
       " ('TEST_0678', 1),\n",
       " ('TEST_0679', 1),\n",
       " ('TEST_0680', 1),\n",
       " ('TEST_0681', 0),\n",
       " ('TEST_0682', 1),\n",
       " ('TEST_0683', 1),\n",
       " ('TEST_0684', 0),\n",
       " ('TEST_0685', 1),\n",
       " ('TEST_0686', 0),\n",
       " ('TEST_0687', 1),\n",
       " ('TEST_0688', 0),\n",
       " ('TEST_0689', 1),\n",
       " ('TEST_0690', 1),\n",
       " ('TEST_0691', 1),\n",
       " ('TEST_0692', 0),\n",
       " ('TEST_0693', 0),\n",
       " ('TEST_0694', 0),\n",
       " ('TEST_0695', 0),\n",
       " ('TEST_0696', 0),\n",
       " ('TEST_0697', 0),\n",
       " ('TEST_0698', 1),\n",
       " ('TEST_0699', 0),\n",
       " ('TEST_0700', 1),\n",
       " ('TEST_0701', 1),\n",
       " ('TEST_0702', 0),\n",
       " ('TEST_0703', 1),\n",
       " ('TEST_0704', 0),\n",
       " ('TEST_0705', 1),\n",
       " ('TEST_0706', 0),\n",
       " ('TEST_0707', 0),\n",
       " ('TEST_0708', 1),\n",
       " ('TEST_0709', 1),\n",
       " ('TEST_0710', 0),\n",
       " ('TEST_0711', 0),\n",
       " ('TEST_0712', 1),\n",
       " ('TEST_0713', 1),\n",
       " ('TEST_0714', 1),\n",
       " ('TEST_0715', 1),\n",
       " ('TEST_0716', 1),\n",
       " ('TEST_0717', 0),\n",
       " ('TEST_0718', 1),\n",
       " ('TEST_0719', 1),\n",
       " ('TEST_0720', 1),\n",
       " ('TEST_0721', 0),\n",
       " ('TEST_0722', 1),\n",
       " ('TEST_0723', 1),\n",
       " ('TEST_0724', 1),\n",
       " ('TEST_0725', 0),\n",
       " ('TEST_0726', 0),\n",
       " ('TEST_0727', 1),\n",
       " ('TEST_0728', 0),\n",
       " ('TEST_0729', 1),\n",
       " ('TEST_0730', 1),\n",
       " ('TEST_0731', 1),\n",
       " ('TEST_0732', 0),\n",
       " ('TEST_0733', 0),\n",
       " ('TEST_0734', 1),\n",
       " ('TEST_0735', 1),\n",
       " ('TEST_0736', 1),\n",
       " ('TEST_0737', 1),\n",
       " ('TEST_0738', 1),\n",
       " ('TEST_0739', 1),\n",
       " ('TEST_0740', 1),\n",
       " ('TEST_0741', 0),\n",
       " ('TEST_0742', 1),\n",
       " ('TEST_0743', 1),\n",
       " ('TEST_0744', 1),\n",
       " ('TEST_0745', 1),\n",
       " ('TEST_0746', 1),\n",
       " ('TEST_0747', 1),\n",
       " ('TEST_0748', 1),\n",
       " ('TEST_0749', 0),\n",
       " ('TEST_0750', 1),\n",
       " ('TEST_0751', 0),\n",
       " ('TEST_0752', 1),\n",
       " ('TEST_0753', 1),\n",
       " ('TEST_0754', 1),\n",
       " ('TEST_0755', 1),\n",
       " ('TEST_0756', 0),\n",
       " ('TEST_0757', 1),\n",
       " ('TEST_0758', 1),\n",
       " ('TEST_0759', 1),\n",
       " ('TEST_0760', 0),\n",
       " ('TEST_0761', 1),\n",
       " ('TEST_0762', 1),\n",
       " ('TEST_0763', 0),\n",
       " ('TEST_0764', 0),\n",
       " ('TEST_0765', 0),\n",
       " ('TEST_0766', 1),\n",
       " ('TEST_0767', 0),\n",
       " ('TEST_0768', 1),\n",
       " ('TEST_0769', 1),\n",
       " ('TEST_0770', 0),\n",
       " ('TEST_0771', 1),\n",
       " ('TEST_0772', 1),\n",
       " ('TEST_0773', 0),\n",
       " ('TEST_0774', 0),\n",
       " ('TEST_0775', 1),\n",
       " ('TEST_0776', 1),\n",
       " ('TEST_0777', 1),\n",
       " ('TEST_0778', 1),\n",
       " ('TEST_0779', 0),\n",
       " ('TEST_0780', 1),\n",
       " ('TEST_0781', 1),\n",
       " ('TEST_0782', 1),\n",
       " ('TEST_0783', 0),\n",
       " ('TEST_0784', 0),\n",
       " ('TEST_0785', 1),\n",
       " ('TEST_0786', 0),\n",
       " ('TEST_0787', 1),\n",
       " ('TEST_0788', 1),\n",
       " ('TEST_0789', 0),\n",
       " ('TEST_0790', 0),\n",
       " ('TEST_0791', 0),\n",
       " ('TEST_0792', 1),\n",
       " ('TEST_0793', 1),\n",
       " ('TEST_0794', 0),\n",
       " ('TEST_0795', 1),\n",
       " ('TEST_0796', 1),\n",
       " ('TEST_0797', 1),\n",
       " ('TEST_0798', 0),\n",
       " ('TEST_0799', 1),\n",
       " ('TEST_0800', 1),\n",
       " ('TEST_0801', 1),\n",
       " ('TEST_0802', 1),\n",
       " ('TEST_0803', 1),\n",
       " ('TEST_0804', 0),\n",
       " ('TEST_0805', 0),\n",
       " ('TEST_0806', 0),\n",
       " ('TEST_0807', 0),\n",
       " ('TEST_0808', 1),\n",
       " ('TEST_0809', 0),\n",
       " ('TEST_0810', 1),\n",
       " ('TEST_0811', 0),\n",
       " ('TEST_0812', 1),\n",
       " ('TEST_0813', 1),\n",
       " ('TEST_0814', 0),\n",
       " ('TEST_0815', 1),\n",
       " ('TEST_0816', 0),\n",
       " ('TEST_0817', 0),\n",
       " ('TEST_0818', 1),\n",
       " ('TEST_0819', 1),\n",
       " ('TEST_0820', 0),\n",
       " ('TEST_0821', 1),\n",
       " ('TEST_0822', 1),\n",
       " ('TEST_0823', 1),\n",
       " ('TEST_0824', 1),\n",
       " ('TEST_0825', 1),\n",
       " ('TEST_0826', 1),\n",
       " ('TEST_0827', 0),\n",
       " ('TEST_0828', 0),\n",
       " ('TEST_0829', 1),\n",
       " ('TEST_0830', 1),\n",
       " ('TEST_0831', 1),\n",
       " ('TEST_0832', 1),\n",
       " ('TEST_0833', 1),\n",
       " ('TEST_0834', 0),\n",
       " ('TEST_0835', 1),\n",
       " ('TEST_0836', 1),\n",
       " ('TEST_0837', 1),\n",
       " ('TEST_0838', 1),\n",
       " ('TEST_0839', 0),\n",
       " ('TEST_0840', 0),\n",
       " ('TEST_0841', 1),\n",
       " ('TEST_0842', 1),\n",
       " ('TEST_0843', 1),\n",
       " ('TEST_0844', 1),\n",
       " ('TEST_0845', 1),\n",
       " ('TEST_0846', 0),\n",
       " ('TEST_0847', 1),\n",
       " ('TEST_0848', 0),\n",
       " ('TEST_0849', 1),\n",
       " ('TEST_0850', 1),\n",
       " ('TEST_0851', 1),\n",
       " ('TEST_0852', 1),\n",
       " ('TEST_0853', 0),\n",
       " ('TEST_0854', 0),\n",
       " ('TEST_0855', 1),\n",
       " ('TEST_0856', 1),\n",
       " ('TEST_0857', 1),\n",
       " ('TEST_0858', 1),\n",
       " ('TEST_0859', 0),\n",
       " ('TEST_0860', 1),\n",
       " ('TEST_0861', 0),\n",
       " ('TEST_0862', 1),\n",
       " ('TEST_0863', 0),\n",
       " ('TEST_0864', 0),\n",
       " ('TEST_0865', 0),\n",
       " ('TEST_0866', 1),\n",
       " ('TEST_0867', 1),\n",
       " ('TEST_0868', 1),\n",
       " ('TEST_0869', 0),\n",
       " ('TEST_0870', 0),\n",
       " ('TEST_0871', 1),\n",
       " ('TEST_0872', 1),\n",
       " ('TEST_0873', 0),\n",
       " ('TEST_0874', 1),\n",
       " ('TEST_0875', 1),\n",
       " ('TEST_0876', 0),\n",
       " ('TEST_0877', 1),\n",
       " ('TEST_0878', 0),\n",
       " ('TEST_0879', 1),\n",
       " ('TEST_0880', 1),\n",
       " ('TEST_0881', 1),\n",
       " ('TEST_0882', 0),\n",
       " ('TEST_0883', 1),\n",
       " ('TEST_0884', 1),\n",
       " ('TEST_0885', 1),\n",
       " ('TEST_0886', 1),\n",
       " ('TEST_0887', 1),\n",
       " ('TEST_0888', 0),\n",
       " ('TEST_0889', 0),\n",
       " ('TEST_0890', 1),\n",
       " ('TEST_0891', 1),\n",
       " ('TEST_0892', 1),\n",
       " ('TEST_0893', 0),\n",
       " ('TEST_0894', 1),\n",
       " ('TEST_0895', 0),\n",
       " ('TEST_0896', 1),\n",
       " ('TEST_0897', 0),\n",
       " ('TEST_0898', 1),\n",
       " ('TEST_0899', 1),\n",
       " ('TEST_0900', 1),\n",
       " ('TEST_0901', 0),\n",
       " ('TEST_0902', 1),\n",
       " ('TEST_0903', 1),\n",
       " ('TEST_0904', 0),\n",
       " ('TEST_0905', 1),\n",
       " ('TEST_0906', 0),\n",
       " ('TEST_0907', 1),\n",
       " ('TEST_0908', 0),\n",
       " ('TEST_0909', 1),\n",
       " ('TEST_0910', 1),\n",
       " ('TEST_0911', 1),\n",
       " ('TEST_0912', 1),\n",
       " ('TEST_0913', 0),\n",
       " ('TEST_0914', 1),\n",
       " ('TEST_0915', 0),\n",
       " ('TEST_0916', 1),\n",
       " ('TEST_0917', 1),\n",
       " ('TEST_0918', 0),\n",
       " ('TEST_0919', 1),\n",
       " ('TEST_0920', 1),\n",
       " ('TEST_0921', 1),\n",
       " ('TEST_0922', 1),\n",
       " ('TEST_0923', 0),\n",
       " ('TEST_0924', 1),\n",
       " ('TEST_0925', 1),\n",
       " ('TEST_0926', 0),\n",
       " ('TEST_0927', 0),\n",
       " ('TEST_0928', 1),\n",
       " ('TEST_0929', 1),\n",
       " ('TEST_0930', 0),\n",
       " ('TEST_0931', 1),\n",
       " ('TEST_0932', 0),\n",
       " ('TEST_0933', 0),\n",
       " ('TEST_0934', 1),\n",
       " ('TEST_0935', 1),\n",
       " ('TEST_0936', 0),\n",
       " ('TEST_0937', 1),\n",
       " ('TEST_0938', 1),\n",
       " ('TEST_0939', 1),\n",
       " ('TEST_0940', 0),\n",
       " ('TEST_0941', 1),\n",
       " ('TEST_0942', 0),\n",
       " ('TEST_0943', 1),\n",
       " ('TEST_0944', 0),\n",
       " ('TEST_0945', 0),\n",
       " ('TEST_0946', 1),\n",
       " ('TEST_0947', 0),\n",
       " ('TEST_0948', 1),\n",
       " ('TEST_0949', 1),\n",
       " ('TEST_0950', 1),\n",
       " ('TEST_0951', 0),\n",
       " ('TEST_0952', 0),\n",
       " ('TEST_0953', 1),\n",
       " ('TEST_0954', 1),\n",
       " ('TEST_0955', 0),\n",
       " ('TEST_0956', 1),\n",
       " ('TEST_0957', 0),\n",
       " ('TEST_0958', 1),\n",
       " ('TEST_0959', 1),\n",
       " ('TEST_0960', 0),\n",
       " ('TEST_0961', 1),\n",
       " ('TEST_0962', 1),\n",
       " ('TEST_0963', 0),\n",
       " ('TEST_0964', 0),\n",
       " ('TEST_0965', 1),\n",
       " ('TEST_0966', 1),\n",
       " ('TEST_0967', 1),\n",
       " ('TEST_0968', 1),\n",
       " ('TEST_0969', 1),\n",
       " ('TEST_0970', 0),\n",
       " ('TEST_0971', 1),\n",
       " ('TEST_0972', 1),\n",
       " ('TEST_0973', 1),\n",
       " ('TEST_0974', 1),\n",
       " ('TEST_0975', 1),\n",
       " ('TEST_0976', 0),\n",
       " ('TEST_0977', 1),\n",
       " ('TEST_0978', 1),\n",
       " ('TEST_0979', 0),\n",
       " ('TEST_0980', 1),\n",
       " ('TEST_0981', 1),\n",
       " ('TEST_0982', 1),\n",
       " ('TEST_0983', 1),\n",
       " ('TEST_0984', 0),\n",
       " ('TEST_0985', 0),\n",
       " ('TEST_0986', 0),\n",
       " ('TEST_0987', 1),\n",
       " ('TEST_0988', 1),\n",
       " ('TEST_0989', 1),\n",
       " ('TEST_0990', 1),\n",
       " ('TEST_0991', 1),\n",
       " ('TEST_0992', 0),\n",
       " ('TEST_0993', 0),\n",
       " ('TEST_0994', 1),\n",
       " ('TEST_0995', 1),\n",
       " ('TEST_0996', 0),\n",
       " ('TEST_0997', 1),\n",
       " ('TEST_0998', 1),\n",
       " ('TEST_0999', 0),\n",
       " ...]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "a = []\n",
    "i = 0\n",
    "for inst in tqdm(dataset):\n",
    "#     print(inst)\n",
    "    response = ask_alpaca(inst, model)\n",
    "#     print(response)\n",
    "    if (response == \"yes\" and inst['is_first_in'] ==1) or (response == \"no\" and inst['is_first_in'] ==0) or (inst['party'] == \"Complainant\" and response == \"yes\"):\n",
    "        a.append((inst['ID'], 1))\n",
    "    else:\n",
    "        a.append((inst['ID'], 0))  \n",
    "    \n",
    "    i += 1\n",
    "\n",
    "a\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebb9ba8-1270-4a58-957d-91d3efe7f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a51026ef-e901-46e1-8bba-d7810de86e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "kk = pd.DataFrame(a, columns=[\"ID\", \"first_party_winner\"])\n",
    "\n",
    "kk.to_csv('submit4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9563f57-dba2-4bb7-8685-99faf4089b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea01416-9350-4014-8c74-0faa628fa1a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd720ab-fc28-47d0-ba0d-8164d9e8c07d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3266229-7592-40e6-a032-c2a74a99ef2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
